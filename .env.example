# MCP Ollama Server Configuration
# Copy to .env and customize for your environment

# Ollama Configuration
OLLAMA_HOST=http://127.0.0.1:11434

# For WSL or Docker environments, you may need:
# OLLAMA_HOST=http://host.docker.internal:11434

# Optional: Set specific model defaults
# DEFAULT_MODEL=llama3.2:1b
# DEFAULT_TIMEOUT=60000

# TTS Configuration (for development notifications)
TTS_ENABLED=true
ENGINEER_NAME=Developer

# TTS Provider (openai recommended for cost optimization)
TTS_PROVIDER=openai

# OpenAI Configuration (if using OpenAI TTS)
# OPENAI_API_KEY=your_openai_api_key_here

# ElevenLabs Configuration (if using ElevenLabs TTS)
# ELEVENLABS_API_KEY=your_elevenlabs_api_key_here

# Debug and Logging
TTS_DEBUG=false
SMART_TTS_ENABLED=true

# Project-specific settings
PROJECT_NAME=mcp-ollama
