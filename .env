# MCP Ollama Server Configuration

# Ollama Configuration - Using WSL/Docker accessible host
OLLAMA_HOST=http://host.docker.internal:11434
# Alternative: Use direct IP if host.docker.internal doesn't work
# OLLAMA_HOST=http://10.0.0.225:11434

# TTS Configuration (for development notifications)
TTS_ENABLED=true
ENGINEER_NAME=Developer

# TTS Provider (openai recommended for cost optimization)
TTS_PROVIDER=openai

# OpenAI Configuration (if using OpenAI TTS)
# OPENAI_API_KEY=your_openai_api_key_here

# ElevenLabs Configuration (if using ElevenLabs TTS)
# ELEVENLABS_API_KEY=your_elevenlabs_api_key_here

# Debug and Logging
TTS_DEBUG=false
SMART_TTS_ENABLED=true

# Project-specific settings
PROJECT_NAME=mcp-ollama
